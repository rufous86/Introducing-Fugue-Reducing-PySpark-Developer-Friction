{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BylxOfcDa_XK"
      },
      "outputs": [],
      "source": [
        "# ! pip install pyspark\n",
        "# ! pip install fugue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mJTIU-syap5p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from typing import Dict\n",
        "\n",
        "input_df = pd.DataFrame({\"id\":[0,1,2], \"value\": ([\"A\", \"B\", \"C\"])})\n",
        "mapping = {\"A\": \"Apple\", \"B\": \"Banana\", \"C\": \"Carrot\"}\n",
        "\n",
        "def map_letter_to_food(df: pd.DataFrame, mapping: Dict) -> pd.DataFrame:\n",
        "    df[\"food\"] = df[\"value\"].map(mapping)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcaqUkPIbMPN",
        "outputId": "9eeda9a5-1393-4c40-e29f-d43c2864f099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----+------+\n",
            "| id|value|  food|\n",
            "+---+-----+------+\n",
            "|  0|    A| Apple|\n",
            "|  1|    B|Banana|\n",
            "|  2|    C|Carrot|\n",
            "+---+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from fugue import transform\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark_session = SparkSession.builder.getOrCreate()\n",
        "\n",
        "df = transform(input_df,\n",
        "               map_letter_to_food,\n",
        "               schema=\"*, food:str\",\n",
        "               params=dict(mapping=mapping),\n",
        "               engine=spark_session\n",
        "               )\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKT1XumLbn19"
      },
      "source": [
        "```python\n",
        "from typing import List, Dict, Any, Iterable\n",
        "\n",
        "def map_letter_to_food2(df: List[Dict[str,Any]], mapping: Dict) -> Iterable[Dict[str,Any]]:\n",
        "    for row in df:\n",
        "        row[\"food\"] = mapping[row[\"value\"]]\n",
        "        yield row\n",
        "\n",
        "def map_letter_to_food3(df: List[List[Any]], mapping: Dict) -> List[List[Any]]:\n",
        "    for row in df:\n",
        "        row.append(mapping[row[1]])\n",
        "    return df\n",
        "\n",
        "def map_letter_to_food4(df: List[List[Any]], mapping: Dict) -> pd.DataFrame:\n",
        "    for row in df:\n",
        "        row.append(mapping[row[1]])\n",
        "    df = pd.DataFrame.from_records(df, columns=[\"id\", \"value\", \"food\"])\n",
        "    return df\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIxWdjbxfXRB",
        "outputId": "59ee05dd-4f0d-4fa5-92c8-92670be9eeca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SparkDataFrame\n",
            "col1:long|col2:long|col3:int\n",
            "---------+---------+--------\n",
            "1        |2        |3       \n",
            "2        |3        |5       \n",
            "3        |4        |7       \n",
            "Total count: 3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from fugue.workflow import FugueWorkflow\n",
        "\n",
        "data = pd.DataFrame({'col1': [1,2,3], 'col2':[2,3,4]})\n",
        "\n",
        "def make_new_col(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df['col3'] = df['col1'] + df['col2']\n",
        "    return df\n",
        "\n",
        "spark_session = SparkSession.builder.getOrCreate()\n",
        "dag = FugueWorkflow()\n",
        "df = dag.df(data)\n",
        "df = df.transform(make_new_col, schema=\"*, col3:int\")\n",
        "dag.run(spark_session)\n",
        "df.result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBpI92_DT5kJ",
        "outputId": "ce18656c-8779-4c50-8bc2-dff5393e1e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SparkDataFrame\n",
            "col1:long|col2:long|col3:int\n",
            "---------+---------+--------\n",
            "1        |2        |3       \n",
            "2        |3        |5       \n",
            "3        |4        |7       \n",
            "Total count: 3\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FugueWorkflowResult()"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from fugue import fsql\n",
        "\n",
        "fsql(\"\"\"SELECT col1, col2 \n",
        "          FROM data \n",
        "     TRANSFORM USING make_new_col SCHEMA *,col3:int \n",
        "         PRINT\"\"\").run(spark_session)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA8cDdW-rN1d",
        "outputId": "2b39c109-a64c-492f-80bd-b886fbfe774d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SparkDataFrame\n",
            "col:long|col2:long\n",
            "--------+---------\n",
            "1       |7        \n",
            "1       |2        \n",
            "2       |9        \n",
            "2       |8        \n",
            "2       |7        \n",
            "3       |6        \n",
            "4       |9        \n",
            "4       |6        \n",
            "4       |4        \n",
            "5       |3        \n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'col': [random.randrange(1, 10, 1) for i in range(20)],\n",
        "    'col2': [random.randrange(1, 10, 1) for i in range(20)]\n",
        "})\n",
        "\n",
        "dag = FugueWorkflow()\n",
        "df = dag.df(data)\n",
        "df = df.partition_by(\"col\", presort=\"col2 desc\", algo=\"even\").take(3)\n",
        "dag.run(spark_session)\n",
        "df.result.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "61ac53437f5c4e510b35ec5227d8eec2a0e1120d76484c7d93efec118f151d42"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
